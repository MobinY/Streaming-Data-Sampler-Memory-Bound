\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{algorithm,algpseudocode,float}
\usepackage{xspace}
\usepackage[usenames]{color}
%\usepackage{hyperref}
\newcommand{\TODO}[1]{\textcolor{red}{\textbf{todo:} \textit{#1}}}

\newcommand{\supp}{\mathop{support}}
\newcommand{\suppfind}[1]{support-finding$_{{#1}}$}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{claim}{Claim}
\newtheorem{remark}{Remark}
\DeclareMathOperator*{\E}{\mathbb{E}}
\let\Pr\relax
\DeclareMathOperator*{\Pr}{\mathbb{P}}
\newcommand{\samp}{\textsf{SAMP}\xspace}
\newcommand{\success}{\textsf{SUCC}\xspace}
\newcommand{\enc}{\textsf{ENC}\xspace}
\newcommand{\dec}{\textsf{DEC}\xspace}
\newcommand{\s}{\textsf{s}\xspace}
\newcommand{\R}{\mathbb{R}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\sk}{\mathsf{sk}}
\newcommand{\diane}{\mathsf{Diane}}
\newcommand{\sketch}{\mathsf{Alice}}
\newcommand{\query}{\mathsf{Bob}}
\newcommand{\eps}{\varepsilon}
\newcommand{\aug}{\mathbf{AugIndex}\xspace}
\newcommand{\ur}{\mathbf{UR}\xspace}
\newcommand{\randcom}{\mathbf{R}}
\newcommand{\findup}[1]{\textsf{FindDuplicate}$({#1})$\xspace}
%\newcommand{\findupk}[1]{\textsf{FindDuplicate}$_k({#1})$\xspace}

\title{Lower bound proofs from augmented indexing}

\begin{document}

\maketitle

\section{Lower bounds proofs using augmented indexing}

Here we show another route to proving $\randcom^{\rightarrow,pub}_\delta(\ur_k^\subset) = \Omega(\min\{n, t\log^2(n/t)\}$ via reduction from augmented indexing. We again separately prove lower bounds for $\randcom^{\rightarrow,pub}_\delta(\ur^\subset)$ and $\randcom^{\rightarrow,pub}_{\frac 15}(\ur_k^\subset)$. Both proofs make use of the following standard lemma.

\begin{lemma}\label{lem:code}
For any integers $u\ge 1$ and $1\le m\le u/(4e)$, there exists a collection $\mathcal S_{u,m} \subset \binom{[u]}m$ with $\log |\mathcal{S}_{u,m}| = \Theta(m\log(u/m))$ such that for all $S\neq S'\in \mathcal S_{u,m}$, $|S\cap S'| < m/2$.
\end{lemma}
\begin{proof}
The proof is via the probabilistic method. We pick $S_1,\ldots,S_N$ independently, each one uniformly at random from $\binom{[u]}m$. Fix $i\neq j\in[N]$. Imagine $S_i$ being fixed and picking the $m$ elements of $S_j$ one by one. Let $X_k$ denote the indicator random variable for the event that the $k$th element picked is also in $S_i$. Then $|S_i\cap S_j| = \sum_{k=1}^m X_k$, and we set $\mu:= \E |S_i\cap S_j|$, which is $m^2/u$ by linearity of expectation. We have $\Pr(|S_i \cap S_j| \ge m/2) = \Pr(|S_i\cap S_j| \ge (1+\delta)\mu)$ for $\delta = u/(2m) - 1$. The $X_k$ are not independent, but they are negatively dependent. Thus the Chernoff bound yields
$$
\Pr(|S_i\cap S_j| \ge (1+\delta)\mu) \le \left(\frac{e^{\delta}}{(1+\delta)^{1+\delta}}\right)^\mu \le \left(\frac{e^{\frac u{2m} - 1}}{(\frac u{2m})^{\frac u{2m}}}\right)^{m^2/u} \le \left(\frac u{2em}\right)^{-\frac m2} .
$$
Setting $N = \sqrt{(u/(2em))^{m/2} - 1}$ so that ${N \choose 2}\leq N^2=(u/(2em))^{m/2} - 1$, by a union bound with positive probability $|S_i\cap S_j| < m/2$ for all $i\neq j$, simultaneously, as desired. Note for this choice of $N$, we have $\log|\mathcal S_{u,m}| = \log N = \Theta(m\log(u/m))$.
\end{proof}

Both our lower bounds in Sections~\ref{sec:aug-delta} and \ref{sec:aug-k} reduce from augmented indexing (henceforth $\aug$) to either $\ur^\subset$ with low failure probability, or $\ur_k^\subset$ with constant failure probability, in the public coin one-way model of communication. We remind the reader of the setup for the $\aug_N$ problem. There are two players, Charlie and Diane. Charlie receives $z\in\{0,1\}^N$ and Diane receives $j^*\in[N]$ together with $z_{j^*+1},\ldots,z_N$. Charlie must send a single message to Diane such that Diane can then output $z_{j^*}$. The following theorem is known.

\begin{theorem}{\cite{MiltersenNSW98}}\label{thm:mnsw}
$\randcom^{\rightarrow,pub}_{1/3}(\aug_N) = \Theta(N)$.
\end{theorem}

We show that if there is an $s$-bit communication protocol $\mathcal P$ for $\ur^\subset$ on $n$-bit vectors with failure probability $\delta$ (or for $\ur_k$ with constant failure probability), that implies the existence of an $s$-bit protocol $\mathcal P'$ for $\aug_N$ for some $N=\Theta(\log\frac 1{\delta}\log^2\frac n{\log\frac 1{\delta}})$ (or $N=\Theta(k\log^2(n/k))$ for $\ur_k$). The lower bound on $s$ then follows from Theorem~\ref{thm:mnsw}.

We also make use of the following lemma.

\begin{lemma}{\cite{JowhariST11}}\label{lem:rand-ur}
Any public coin protocol for $\ur^\subset$ can be turned into one that outputs every index $i\in[n]$ with $x_i\neq y_i$ with the same probability. The number of bits sent, failure probability, and number of rounds do not change. Similarly, any $\ur_k^\subset$ protocol can be turned into one in which all subsets of $[n]$ of size $\min\{k, \|x-y\|_0\}$ on which $x, y$ differ are equally likely to be output.
\end{lemma}

Henceforth we assume $\mathcal P$ outputs random differing indices, which is without loss of generality by Lemma~\ref{lem:rand-ur}.

\subsection{Lower bound on $\randcom^{\rightarrow,pub}_\delta(\ur^\subset)$.}\label{sec:aug-delta}

Set $t = \log \frac 1{\delta}$. In this section we assume $t < n/(4e)$ and show $\randcom^{\rightarrow,pub}_\delta(\ur^\subset) = \Omega(t\log^2(n/t))$. This implies a lower bound of $\Omega(\min\{n, t\log^2(n/t)\})$ for all $\delta>0$ bounded away from $1$.

As mentioned, we assume we have an $s$-bit protocol $\mathcal P$ for $\ur^\subset$ with failure probability $\delta$, with players Alice and Bob.We use $\mathcal P$ to give an $s$-bit protocol $\mathcal P'$ for $\aug_N$, which has players Charlie and Diane, for $N = \Theta(t\log^2(n/t))$.

The protocol $\mathcal P'$ operates as follows. Without loss of generality we may assume that, using the notation of Lemma~\ref{lem:code}, $|\mathcal S_{u,m}|$ is a power of $2$ for $u, m$ as in the lemma statement. This is accomplished by simply rounding $|\mathcal S_{u,m}|$ down to the nearest power of $2$ by removing elements arbitrarily. Also, define $L = c\log(n/t)$ for some sufficiently small constant $c\in(0,1)$ to be determined later. Now, Charlie partitions the bits of his input $z\in\{0,1\}^N$ into $L$ consecutive sequences of bits such that the $i$th chunk of bits for each $i\in[L]$ can be viewed as specifying an element $S_i\in \mathcal S_{u_i,m}$ for $u_i = \frac n{100^i\cdot L}$ and $m = ct$. Lemma~\ref{lem:code} gives $\log|\mathcal S_{u_i,m}| = \Theta(m\log(u_i/m))$, which is $\Theta(t\log(n/t))$ for $c < 1/14$. Thus $N = \Theta(L\cdot t\log(n/t)) = \Theta(t\log^2(n/t))$. Given these sets $S_1,\ldots,S_L$, we now discuss how Charlie generates a vector $x\in\{0,1\}^n$. Charlie then simulates Alice on $x$ to generate the message Alice would have send to Bob in protocol $\mathcal P$, then sends that same message to Diane.

To generate $x\in\{0,1\}^n$, assume Charlie and Diane have agreed on an arbitrary bijection from 
$$A = \bigcup_{i=1}^L (\{i\} \times [u_i]\times [100^i])$$
to $[n]$. This is possible since $|A| = n$. Henceforth we think of $x$ as being indexed by $A$. Then Charlie defines $x$ to be the indicator vector $\mathbf{1}_S$ of the set
$$
S = \bigcup_{i=1}^L (\{i\} \times S_i \times [100^i]) 
$$
then sends a message $M$ to Diane, equal to Alice's message with input $\mathbf{1}_S$. This completes the description of Charlie's behavior in the protocol $\mathcal P'$.

We describe how Diane uses $M$ to solve $\aug_N$. Diane's input $j^*\in[N]$ lies in some chunk $i^*\in[L]$. We now show how Diane can use $\mathcal P$ to recover $S_{i^*}$ with probability $2/3$ (and thus in particular recover $z_{j^*}$). Since Diane knows $z_j$ for $j>j^*$, she knows $S_i$ for $i>i^*$. She can then execute the following algorithm.


\begin{algorithm}[H] 
  \caption{Behavior of Diane in $\mathcal P'$ for $\ur^\subset$.} \label{algo:diane1}
  \begin{algorithmic}[1]
    \Procedure{$\diane$}{$M$}
    \State $T \leftarrow \bigcup_{i=i^*+1}^L (\{i\} \times S_i \times [100^i])$
    \State $T_{i^*}\leftarrow \emptyset$
    \While {$|T_{i^*}| < \frac m2$}
      \State $(i,a,r)\leftarrow \query(M, \mathbf{1}_T)$
      \State $T\leftarrow T \cup ((i,a) \times [100^i])$
      \If {$i=i^*$} 
        \State $T_{i^*} \leftarrow T_{i^*}\cup \{a\}$
      \EndIf
    \EndWhile
    \State \Return the unique $S\in \mathcal S_{u_{i^*},m}$ with $T_{i^*}\subset S$ 
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

In Algorithm~\ref{algo:diane1} Diane is building up a subset $T_{i^*}$ of $S_{i^*}$. Once $|T_{i^*}| \ge |S_{i^*}|/2 = m/2$, Diane can uniquely recover $S_{i^*}$ by the limited intersection property of $\mathcal{S}_{u_i,m}$ guaranteed by Lemma~\ref{lem:code}. Until then, she uses $\mathcal P$ to recover uniformly random elements of $S\backslash T$. Since the elements of $S_i$ appear with frequency $100^i$ in $S\backslash T$, they are more likely to be returned by Bob. Indeed, as long as $T_{i^*}\le m/2$, at least $m/2$ elements remain in $S_{i^*}\backslash T_{i^*}$, implying Bob's output $(i,a,r)$ satisfies
\begin{equation}
\Pr(i = i^*) \ge \frac{\frac m2\cdot 100^{i^*}}{\frac m2\cdot 100^{i^*} + m\cdot \sum_{i=1}^{i^*-1} 100^i} = \frac{\frac 12\cdot 100^{i^*}}{\frac 12\cdot 100^{i^*} + \frac {100}{99}(100^{i^*-1} - 1)} > \frac{49}{50} . \label{eqn:istar-likely}
\end{equation}
Meanwhile, as long as the \textbf{while} loop has not ended, for any $1\le j< i^*$
\begin{equation}
\Pr(i = j) \le \frac{m\cdot 100^j}{\frac m2\cdot 100^{i^*}} \le 2\cdot 100^{-(i^*-j)} \le 50^{-(i^*-j)} . \label{eqn:others-unlikely}
\end{equation}

Let $Q_i$ for $i\in [L]$ denote $\{i\} \times S_i \times [100^i]$. Let $\mathcal{E}_T$ be the probabilistic event that $\query(M, \mathbf{1}_T)$ succeeds in returning a uniformly random element in $S\backslash T$, and let $\mathcal{T}$ be the collection of all $T\subset S$ such that (1) $Q_i\subset T$ for all $i>i^*$, and (2) for each $i < i^*$, $|T\cap Q_i| \le 100^i\cdot  m/2^{i^*-i}$. Let $\mathcal{F}$ be the event that in the first $m$ iterations of the \textbf{while} loop of Algorithm~\ref{algo:diane1}, Diane never stores a set $T\notin\mathcal{T}$. Let $\mathcal{G}$ be the event that the \textbf{while} loop terminates within the first $m$ iterations. Then note that $(\wedge_{T\in\mathcal T} \mathcal E_T) \wedge \mathcal F\wedge \mathcal G$ occurring implies that Diane succeeds in recovering $S_{i^*}$. It then suffices to show $\Pr(\neg((\wedge_{T\in\mathcal T} \mathcal E_T) \wedge \mathcal F\wedge \mathcal G)) < 1/3$. We show this via the union bound.

\medskip

\noindent $\mathbf{(\wedge_{T\in\mathcal T} \mathcal E_T):}$ $\Pr(\neg(\wedge_{T\in\mathcal T} \mathcal E_T)) \le \delta\cdot |\mathcal T|$, again by the union bound. Then
\allowdisplaybreaks
\begin{align*}
|\mathcal T| &\le 2^m \cdot \prod_{i=1}^{i^*-1}\left(\sum_{r=0}^{\frac m{2^{i^*-i}}} \binom mr\right)\text{ (the }2^m\text{ term comes from }S_{i^*}\text{)}\\
{}&\le 2^m \cdot \prod_{i=1}^{i^*-1} \binom{m + \frac m{2^{i^* - i}}}{\frac m{2^{i^* - i}}}\\
{}&\le 2^m \cdot \prod_{i=1}^{i^*-1} (2e\cdot 2^{i^*-i})^{\frac m{2^{i^* - i}}}\text{ (using }\binom nk \le (en/k)^k\textrm{)}\\
{}&\le 2^{O(m)} \cdot 2^{m\cdot O(\sum_{j=1}^\infty j 2^{-j})} \\
{}& \le 2^{O(m)}
\end{align*}
Thus $\delta \cdot |\mathcal T| \le 1/20$ for $m = c\log(1/\delta)$ for $c$ a sufficiently small constant.

\medskip

\noindent $\mathbf{(\mathcal F)}:$ By \eqref{eqn:others-unlikely}, the expected number of items recovered by Bob from $S_i$ for $i<i^*$ in the first $m$ iterations is at most $m/50^{i^*-i}$. Thus the probability of recovering more than $m/2^{i^*-i}$ items from $S_i$ is at most $(1/25)^{i^*-i}$ by Markov's inequality.  Thus
$$
\Pr(\neg\mathcal F) \le \sum_{i=1}^{i^*-1}\left(\frac 1{25}\right)^{i^*-i} < \frac 1{24}
$$

\noindent $\mathbf{(\mathcal G)}:$ By \eqref{eqn:istar-likely}, we expect at most $m/50$ of the first $m$ iterations to fail to reveal an element of $S_i\backslash T_{i^*}$ from Bob's query. Thus the probability that more than $m/2$ iterations fail to do so is at most $1/25$ by Markov's inequality. Thus $\Pr(\neg\mathcal{G}) \le 1/25$.

\medskip

We have thus established that $\Pr(\neg((\wedge_{T\in\mathcal T} \mathcal E_T) \wedge \mathcal F\wedge \mathcal G)) \le 1/20 + 1/24 + 1/25 < 1/3$, as desired, showing the following theorem.

\begin{theorem}
For any $0<\delta<1/2$ and integer $n\ge 1$ with $\log \frac 1{\delta} < n/(4e)$, $\randcom^{\rightarrow,pub}_\delta(\ur^\subset) \ge \randcom^{\rightarrow,pub}_{1/3}(\aug_N)$ for $N = \Theta(\log\frac 1{\delta} \log^2 \frac n{\log \frac 1{\delta}})$.
\end{theorem}

\begin{corollary}
For any $0<\delta<1/2$ and integer $n\ge 1$, $\randcom^{\rightarrow,pub}_\delta(\ur^\subset) = \Omega(\min\{n, \log\frac 1{\delta} \log^2 \frac n{\log \frac 1{\delta}}\})$.
\end{corollary}

\subsection{Lower bound on $\randcom^{\rightarrow,pub}_{\frac 15}(\ur_k^\subset)$.}\label{sec:aug-k}

The idea for lower bounding $\randcom^{\rightarrow,pub}_{\frac 15}(\ur_k^\subset)$ is as in Section~\ref{sec:aug-delta}, but slightly simpler. That is because for the protocol $\mathcal P'$ for $\aug_N$, Diane will not make adaptive queries to Bob in the protocol $\mathcal P$ for $\ur_k^\subset$. Rather, she will only make one query using Bob and will be able to decide $\aug_N$ with good probability from that single query.

Again Charlie receives $z\in\{0,1\}^N$ and Diane receives $j^*$ and $z_{j^*+1},\ldots,z_N$ and they want to solve $\aug_N$. Charlie views his input as consisting of $L$ blocks for $L = c\log(n/k)$ for a sufficiently small constant $c\in(0,1)$, and the $i$th block for $i\in[L]$ specifies a set $S_i \in \mathcal S_{u_i,m}$ for $m = ck$ and $u_i = n/(100^i L)$. As before, for $c$ sufficiently small we have $N = \Theta(L\cdot k\log(n/k)) = \Theta(k\log^2(n/k))$. The bijection $A$ and set $S$ are defined exactly as in Section~\ref{sec:aug-delta}, and Charlie simulates Alice to send the message $M$ to Diane that Alice would have sent to Bob on input $\mathbf{1}_S$. Again, Diane knows $S_i$ for $i>i*$, where $j^*$ lies in the $i^*$th block of bits. Diane's algorithm to produce her output is then described in Algorithm~\ref{algo:diane2}.

\begin{algorithm}%[H] 
  \caption{Behavior of Diane in $\mathcal P'$ for $\ur_k^\subset$.} \label{algo:diane2}
  \begin{algorithmic}[1]
    \Procedure{$\diane$}{$M$}
    \State $T \leftarrow \bigcup_{i=i^*+1}^L (\{i\} \times S_i \times [100^i])$
    \State $T_{i^*}\leftarrow \emptyset$
    \State $B\leftarrow \query(M, \mathbf{1}_T)$
    \For{$(i,a,r)\in B$}
      \If {$i=i^*$ and $a\notin T$}
        \State $T_{i^*} \leftarrow T_{i^*}\cup \{a\}$
      \EndIf
    \EndFor
    \If {$|T_{i^*}| < \frac m2$}
      \State \Return \textsf{Fail}
    \Else
      \State \Return the unique $S\in \mathcal S_{u_{i^*},m}$ with $T_{i^*}\subset S$ 
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

Recall Bob, when he succeeds, returns $\min\{k, |S\backslash T|\} = k$ uniformly random elements from $S\backslash T$. Meanwhile, $S_{i^*}$ only has $m = ck$ elements for some small constant $c$. As in Section~\ref{sec:aug-delta}, almost all of the support of $S\backslash T$ comes from items in block $i^*$, and hence we expect almost all our $k$ samples to come from (and be uniform in) items corresponding to elements of $S_{i^*}$. 

We now provide a formal analysis. Henceforth we condition on Bob succeeding, which happens with probability $4/5$. The number of elements in $S\backslash T$ corresponding to an element of $S_{i^*}$ is $100^{i^*} m$, whereas the number of elements corresponding to an element of $S_i$ for $i < i^*$ is
$$
m\cdot \sum_{i=1}^{i^*-1} 100^i = \frac m{99}\cdot (100^{i^*} - 1) < \frac m{99}\cdot 100^{i^*}
$$
Thus, we expect at most $k/99$ elements in $B$ to correspond to elements in $S_i$ for $i\neq i^*$, and the probability that we have at least $k/9$ such elements in $B$ is less than $1/10$ by Markov's inequality. We henceforth condition on having less than $k/9$ such elements in $B$. Now we know $B$ contains at least $8k/9$ elements corresponding to $S_{i^*}$, chosen uniformly from $S_{i^*}\times [100^i]$. For any given element $a\in S_{i^*}$, the probability that none of the elements in $B$ from $S_{i^*}$ correspond to $a$ is $(1 - 1/m)^{\frac 89 k} \le e^{-(8/9)k/m} < 1/30$ for $c$ sufficiently small (where $m = ck$). Thus the expected number of $a\in S_{i^*}$ not covered by $B$ is less than $m/30$. Thus the probability that fewer than $m/2$ elements are covered by $B$ is a most $1/15$ by Markov's inequality (and otherwise, Diane succeeds). Thus, the probability that Diane succeeds is at least $4/5\cdot 9/10 \cdot 14/15 > 2/3$. We have thus shown the following theorem.

\begin{theorem}
For any integers $1\le k \le n$, $\randcom^{\rightarrow,pub}_{\frac 15}(\ur_k^\subset) \ge \randcom^{\rightarrow,pub}_{\frac 13}(\aug_N)$ for $N = \Theta(k\log^2(n/k))$.
\end{theorem}

\begin{corollary}
For any integers $1\le k \le n$, $\randcom^{\rightarrow,pub}_{\frac 15}(\ur_k^\subset) = \Omega(\min\{n, k\log^2(n/k)\})$.
\end{corollary}

\begin{remark}
\textup{
One may wish to understand $\randcom^{\rightarrow,pub}_\delta(\ur_k^\subset)$ for $\delta$ near $1$ (or at least, larger than $1/2$). Such a lower bound is given in Section~\TODO{cite the other proof in merged paper}. The proof given above as written would yield no lower bound in this regime for $\delta$ since $\aug$ is in fact easy when the failure probability is allowed to be least $1/2$ (Charlie can send no message at all, and Diane can simply guess $z_{j^*}$ via a coin flip). One can however get a handle on $\randcom^{\rightarrow,pub}_\delta(\ur_k^\subset)$ by instead directly reducing from the following variant of augmented indexing: Charlie receives $D\in \mathcal S_{u_1,m}\times \cdots \times \mathcal S_{u_L, m}$ and Diane receives $j^*\in[L]$ and $D_{j^*+1},\ldots,D_L$ and must output $D_{j^*}$, where the $u_i$ are as above. One can show that unless Charlie sends almost his entire input, Diane cannot have success probability significantly better than random guessing (which has success probability $O(\max_{i\in L} 1/|\mathcal S_{u_i, m}|)$). The proof is nearly identical to the analysis of augmented indexing over large domains \cite{ErgunJS10,JayramW13}. Indeed, the problem is even almost identical, except that here we consider Charlie receiving a vector whose entries come from different alphabet sizes (since the $|\mathcal S_{u_i,m}|$ are different), whereas in \cite{ErgunJS10,JayramW13} all the entries come from the same alphabet.
}
\end{remark}

\bibliographystyle{alpha}
\bibliography{shortbib}

\end{document}
