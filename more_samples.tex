\subsection{Communication Lower Bound for $\ur_k^\subset$}\label{sec:k-samples-lb}

In this section, we prove the lower bound $\randcom^{\rightarrow,pub}_{1/2}(\ur^\subset_k) = \Omega(\min\{n, k\log^2 \frac{n}{k}\})$. In fact, our lower bound holds for any failure probability $\delta$ bounded away from $1$. Let $\mathcal{P}$ denote a $\ur_k^\subset$-protocol where Alice sends $\sketch_k(x)$ to Bob, and Bob outputs $\query_k(\sketch_k(x), y)$.  We consider the following encoding/decoding scheme $(\enc_k, \dec_k)$ for $S\in {[n] \choose m}$.  $\enc_k$ computes $M\leftarrow \sketch_k(\mathbf{1}_S)$ as part of its message. In addition, $\enc_k$ includes $B\subseteq S$ constructed as follows, spending $\lceil\log{n\choose |B|}\rceil$ bits.  Initially $B= S$, and $\enc_k$ proceeds in $R=\Theta(\log (n/k))$ rounds.  Let $S_0=S\supseteq S_1\supseteq \ldots \supseteq S_R$ where $S_r$ is generated by sub-sampling each element in $S_{r-1}$ with probability $\frac{1}{2}$.  In round $r$ ($r=1,\ldots, R$), $\enc_k$ tries to obtain $k$ elements from $S_{r-1}$ by invoking $\query_k(M, \mathbf{1}_{S\backslash S_{r-1}})$, denoted by $A_k$, and removes $A_k\cap (S_{r-1}\backslash S_{r})$ (whose expected size is $\frac{k}{2}$) from $B$.  Note that $\dec_k$ is able to recover the elements in $A_k\cap (S_{r-1}\backslash S_{r})$.  For each round the failure probability of $\query_k$ is at most $\delta$.  Thus we have $\E(|S|-|B|)\ge \frac{k}{2}\cdot (1-\delta) \cdot R=\Omega(k\log\frac{n}{k})$.  Furthermore, each element contains $\Theta(\log \frac{n}{k})$ bits of information, thus yielding a lower bound of $\Omega(k\log^2\frac{n}{k})$ bits.

In this section we assume $k \le n/2^{10}$, since for larger $n$ we have an $\Omega(n)$ lower bound.

\subsubsection{Encoding/decoding scheme}
\begin{algorithm}[H] 
  \caption{Variables Shared by Encoder $\enc_k$ and Decoder $\dec_k$.} \label{algo:para4}
  \begin{algorithmic}[1] 
    \State $m\leftarrow \lfloor \sqrt{nk} \rfloor$
    \State $R\leftarrow \lfloor \frac{1}{2}\log (n/k) - 2 \rfloor$ \Comment{Note that $R\ge 3$ because $k\le \frac{n}{2^{10}}$}
    \State $T_0\leftarrow [n]$
    \For {$r = 1, \ldots, R$}
      \State $T_r\leftarrow \emptyset$
      \State For each $a\in T_{r-1}$, $T_r\leftarrow T_r\cup \{a\}$ with probability $\frac{1}{2}$ \Comment{We have $S_r=S\cap T_r$}
    \EndFor
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H] 
  \caption{Encoder $\enc_k$.} \label{algo:enc4}
  \begin{algorithmic}[1]
    \Procedure{$\enc_k$}{$S$}
    \State $M \leftarrow \sketch_k(\mathbf{1}_S)$
    \State $A\leftarrow \emptyset$
    \For {$r=1,\ldots,R$}
    \State $A_r\leftarrow \query_k(M, \mathbf{1}_{S\backslash (S\cap T_{r-1})})$
    \If {$A_r\subseteq S\cap T_{r-1}$} \Comment{i.e. if $A_r$ is valid}
      \State $b_r\leftarrow 1$ \Comment{$b$ is a binary string of length $R$, indicating if $\query_k$ succeeds in round $r$}
      \State $A\leftarrow A \cup (A_r\cap (T_{r-1}\backslash T_r))$
    \Else 
      \State $b_r\leftarrow 0$
    \EndIf
    \EndFor
      \State \Return ($M$, $S\backslash A$, $b$) 
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H] 
  \caption{Decoder $\dec_k$.} \label{algo:dec4}
  \begin{algorithmic}[1]
    \Procedure{$\dec_k$}{$M$, $B$, $b$}
    \State $A\leftarrow \emptyset$
    \State $C_0 \leftarrow \emptyset$
    \For {$r=1,\ldots,R$}
      \State $C_r\leftarrow C_{r-1}$
      \If {$b_r=1$}
        \State $A_r\leftarrow \query_k(M, \mathbf{1}_{C_{r-1}})$ \Comment{Invariant: $C_r=S\backslash (S\cap T_r)$}
        \State $A\leftarrow A \cup (A_r\cap (T_{r-1}\backslash T_r))$
        \State $C_r\leftarrow C_r \cup (A_r\cap (T_{r-1}\backslash T_r))$
      \EndIf
      \State $C_r\leftarrow C_r \cup (B\cap (T_{r-1}\backslash T_r))$
    \EndFor
    \State \Return $B\cup A$ 
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsubsection{Analysis}

%\TODO{Check if the following proof looks good. Note that $R < \log n$, so we can afford sending $b$ directly as a binary string. It is sufficient to ensure that $(1-\delta)k\log^2 (n/k)=\Omega(\log n)$. (previous todo: the below theorem should work for arbitrary $\delta<1$, not just $\delta< 1/2$. I think also one should huffman-encode the $b$ vector as Zhengyu suggested, which would get a constant factor of $1-\delta$ in the lower bound)}

\begin{theorem}\label{thm:urk}
  $\randcom^{\rightarrow,pub}_\delta(\ur_k^\subset) = \Omega((1-\delta)k\log^2 \frac{n}{k} )$, given that $1 \le k \le \frac{n}{2^{10}}$ and $0<\delta \le 1-\frac{50\log n}{k\log^2(n/k)}$.
\end{theorem}
\begin{proof}
Let $S_r=S\cap T_r$.  Let $\success$ denote the event that $|S\cap T_R|=|S_R|\ge k$.  Note that $\E|S_R|=\frac{1}{2^R}m=4k$. By the Chernoff bound, $\Pr(\success)\ge \frac{1}{2}$.  In the following, we argue conditioned on $\success$. Namely, in each round $r$, there are at least $k$ items in $S_r$.
  
Similar to Lemma~\ref{lemma:zero-fail-prob}, we can prove the protocol $(\enc_k,\dec_k)$ always succeeds.  By Lemma~\ref{lemma:lb-meta}, we have $\s\ge \log (^n_m) - \s' -2$, where $\s'=\log n + R+ \E \log (^n_{|B|})$.  The size of $B$ is $|B|=|S|-\sum_{r=1}^{R}{(b_r \cdot |A_r \cap (S_{r-1}\backslash S_r)|)}$.  The randomness used by $\mathcal{P}$ is independent from $S\backslash S_{r-1}$ for every $r\in[R]$.  Therefore, $\E b_r\ge 1-\delta$, and $b_r$ is independent from $|A_r \cap (S_{r-1}\backslash S_r)|$.  We have $\E|A_r \cap (S_{r-1}\backslash S_r)|=\frac{k}{2}$, and thus $\E(|S|-|B|)\ge \frac{(1-\delta)kR}{2}$.  By Lemma~\ref{lemma:bits-saving}, $\log (^n_m)-\E\log (^n_{|B|})\ge \frac{(1-\delta)kR}{2}\cdot \log (\frac{n}{m}-1) \ge \frac{(1-\delta)kR}{5}\log (\frac{n}{k})$.  Moreover, $R\le \log n$ and $\log n \le \frac{(1-\delta)kR}{12}\log \frac{n}{k}$.  Thus we have $\s = \Omega((1-\delta)kR\log\frac{n}{k}) = \Omega((1-\delta)k\log^2 \frac{n}{k} )$.
\end{proof}
